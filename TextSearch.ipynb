{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a191ba5-3063-4391-8a13-b93373a44403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/CLIP.git\n",
      "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-49o0a8du\n",
      "  Running command git clone -q https://github.com/openai/CLIP.git /tmp/pip-req-build-49o0a8du\n",
      "  Resolved https://github.com/openai/CLIP.git to commit d50d76daa670286dd6cacf3bcd80b5e4823fc8e1\n",
      "Collecting ftfy\n",
      "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
      "\u001b[K     |████████████████████████████████| 53 kB 98 kB/s  eta 0:00:011\n",
      "\u001b[?25hCollecting regex\n",
      "  Downloading regex-2022.8.17-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (752 kB)\n",
      "\u001b[K     |████████████████████████████████| 752 kB 4.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from clip==1.0) (4.63.0)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from clip==1.0) (1.12.0)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from clip==1.0) (0.13.0)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in /opt/conda/lib/python3.7/site-packages (from ftfy->clip==1.0) (0.2.5)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from torch->clip==1.0) (4.1.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision->clip==1.0) (1.21.5)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchvision->clip==1.0) (2.27.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision->clip==1.0) (9.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision->clip==1.0) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision->clip==1.0) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision->clip==1.0) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision->clip==1.0) (1.26.8)\n",
      "Building wheels for collected packages: clip\n",
      "  Building wheel for clip (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369400 sha256=569a5ca4854ee3c4b5f1900600d7926e5b0e251c2e3eefad843f937cc35c5984\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-jv9t9h9b/wheels/fd/b9/c3/5b4470e35ed76e174bff77c92f91da82098d5e35fd5bc8cdac\n",
      "Successfully built clip\n",
      "Installing collected packages: regex, ftfy, clip\n",
      "Successfully installed clip-1.0 ftfy-6.1.1 regex-2022.8.17\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Torch was already installed - you might need to figure out torch + cuda setup for your GPU\n",
    "\n",
    "!pip install git+https://github.com/openai/CLIP.git\n",
    "!python -m pip install pytube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe92f068-4692-4b43-9420-4ff41b2a5ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytube import Channel\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82ad6dc5-c9af-43b3-b530-367db683c35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Channel(\"https://www.youtube.com/c/DaveThielking/videos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2cd17543-bf8a-434f-8db6-fbdcc5494f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "for vid in c.videos:\n",
    "    if vid.title.startswith(\"90\"):\n",
    "        vid.streams.filter(progressive=True, file_extension='mp4').first().download(\"videos\", re.sub('[^A-Za-z0-9]+', '_', vid.title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9661a5ca-36a8-4cab-9aae-0993de731efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(\"videos\"):\n",
    "    cmd = f\"ffmpeg -i videos/{file} -r 0.5 images/{file}_%04d.png\"\n",
    "    print(file)\n",
    "    print(cmd)\n",
    "    if file.startswith(\".\"):\n",
    "        continue\n",
    "    ! $cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "04ef3e1a-8e4a-4235-856b-6600d4fd3a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 338M/338M [00:13<00:00, 26.7MiB/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f6e4db9f-d159-45ba-b946-29474cb1a7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names = [f'images/{file}' for file in sorted(os.listdir(\"images\")) if not file.startswith(\".\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f9e1ffc7-61b9-45c2-bd9e-866314fd6059",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_image_names = {}\n",
    "\n",
    "for image_name in image_names:\n",
    "    g = image_name.split(\"_\")[-2]\n",
    "    if g in grouped_image_names:\n",
    "        grouped_image_names[g].append(image_name)\n",
    "    else:\n",
    "        grouped_image_names[g] = [image_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e179eb2-a20f-41ed-8ff7-a4c8bab70a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Volume #100, Highest Log Prob: 23.109375, Best frame:, images/90_s_Commercials_Ontario_Vol_100_0124.png\n",
      "------\n",
      "Processed Volume #101, Highest Log Prob: 23.265625, Best frame:, images/90_s_Commercials_Ontario_Vol_101_0050.png\n",
      "------\n",
      "Processed Volume #102, Highest Log Prob: 24.859375, Best frame:, images/90_s_Commercials_Ontario_Vol_102_0165.png\n",
      "------\n",
      "Processed Volume #103, Highest Log Prob: 25.96875, Best frame:, images/90_s_Commercials_Ontario_Vol_103_0092.png\n",
      "------\n",
      "Processed Volume #104, Highest Log Prob: 24.953125, Best frame:, images/90_s_Commercials_Ontario_Vol_104_0083.png\n",
      "------\n",
      "Processed Volume #105, Highest Log Prob: 23.703125, Best frame:, images/90_s_Commercials_Ontario_Vol_105_0294.png\n",
      "------\n",
      "Processed Volume #106, Highest Log Prob: 25.421875, Best frame:, images/90_s_Commercials_Ontario_Vol_106_0106.png\n",
      "------\n",
      "Processed Volume #107, Highest Log Prob: 25.40625, Best frame:, images/90_s_Commercials_Ontario_Vol_107_0217.png\n",
      "------\n",
      "Processed Volume #108, Highest Log Prob: 25.359375, Best frame:, images/90_s_Commercials_Ontario_Vol_108_0180.png\n",
      "------\n",
      "Processed Volume #109, Highest Log Prob: 27.296875, Best frame:, images/90_s_Commercials_Ontario_Vol_109_0268.png\n",
      "-------\n",
      "MATCH > 27:\n",
      "Log Prob: 27.296875 Frame: images/90_s_Commercials_Ontario_Vol_109_0268.png\n",
      "------\n",
      "Processed Volume #10, Highest Log Prob: 27.046875, Best frame:, images/90_s_Commercials_Ontario_Vol_10_0203.png\n",
      "-------\n",
      "MATCH > 27:\n",
      "Log Prob: 27.046875 Frame: images/90_s_Commercials_Ontario_Vol_10_0203.png\n",
      "------\n",
      "Processed Volume #Edition, Highest Log Prob: 27.65625, Best frame:, images/90_s_Commercials_Ontario_Vol_110_The_Sears_Edition_0233.png\n",
      "-------\n",
      "MATCH > 27:\n",
      "Log Prob: 27.65625 Frame: images/90_s_Commercials_Ontario_Vol_110_The_Sears_Edition_0233.png\n",
      "------\n",
      "Processed Volume #111, Highest Log Prob: 25.34375, Best frame:, images/90_s_Commercials_Ontario_Vol_111_0221.png\n",
      "------\n",
      "Processed Volume #112, Highest Log Prob: 25.75, Best frame:, images/90_s_Commercials_Ontario_Vol_112_0124.png\n",
      "------\n",
      "Processed Volume #113, Highest Log Prob: 23.671875, Best frame:, images/90_s_Commercials_Ontario_Vol_113_0086.png\n",
      "------\n",
      "Processed Volume #114, Highest Log Prob: 24.234375, Best frame:, images/90_s_Commercials_Ontario_Vol_114_0103.png\n",
      "------\n",
      "Processed Volume #115, Highest Log Prob: 26.046875, Best frame:, images/90_s_Commercials_Ontario_Vol_115_0235.png\n",
      "------\n",
      "Processed Volume #116, Highest Log Prob: 24.65625, Best frame:, images/90_s_Commercials_Ontario_Vol_116_0220.png\n",
      "------\n",
      "Processed Volume #117, Highest Log Prob: 23.78125, Best frame:, images/90_s_Commercials_Ontario_Vol_117_0131.png\n",
      "------\n",
      "Processed Volume #118, Highest Log Prob: 24.09375, Best frame:, images/90_s_Commercials_Ontario_Vol_118_0240.png\n",
      "------\n",
      "Processed Volume #119, Highest Log Prob: 26.234375, Best frame:, images/90_s_Commercials_Ontario_Vol_119_0128.png\n",
      "------\n",
      "Processed Volume #11, Highest Log Prob: 24.0625, Best frame:, images/90_s_Commercials_Ontario_Vol_11_0071.png\n",
      "------\n",
      "Processed Volume #120, Highest Log Prob: 27.421875, Best frame:, images/90_s_Commercials_Ontario_Vol_120_0056.png\n",
      "-------\n",
      "MATCH > 27:\n",
      "Log Prob: 27.421875 Frame: images/90_s_Commercials_Ontario_Vol_120_0056.png\n",
      "------\n",
      "Processed Volume #121, Highest Log Prob: 27.453125, Best frame:, images/90_s_Commercials_Ontario_Vol_121_0121.png\n",
      "-------\n",
      "MATCH > 27:\n",
      "Log Prob: 27.453125 Frame: images/90_s_Commercials_Ontario_Vol_121_0121.png\n",
      "Log Prob: 27.40625 Frame: images/90_s_Commercials_Ontario_Vol_121_0125.png\n",
      "------\n",
      "Processed Volume #122, Highest Log Prob: 24.953125, Best frame:, images/90_s_Commercials_Ontario_Vol_122_0061.png\n",
      "------\n",
      "Processed Volume #123, Highest Log Prob: 23.5625, Best frame:, images/90_s_Commercials_Ontario_Vol_123_0227.png\n",
      "------\n",
      "Processed Volume #124, Highest Log Prob: 27.375, Best frame:, images/90_s_Commercials_Ontario_Vol_124_0075.png\n",
      "-------\n",
      "MATCH > 27:\n",
      "Log Prob: 27.375 Frame: images/90_s_Commercials_Ontario_Vol_124_0075.png\n",
      "Log Prob: 27.265625 Frame: images/90_s_Commercials_Ontario_Vol_124_0064.png\n",
      "------\n",
      "Processed Volume #125, Highest Log Prob: 22.96875, Best frame:, images/90_s_Commercials_Ontario_Vol_125_0011.png\n",
      "------\n",
      "Processed Volume #126, Highest Log Prob: 23.34375, Best frame:, images/90_s_Commercials_Ontario_Vol_126_0143.png\n",
      "------\n",
      "Processed Volume #127, Highest Log Prob: 30.140625, Best frame:, images/90_s_Commercials_Ontario_Vol_127_0233.png\n",
      "-------\n",
      "MATCH > 27:\n",
      "Log Prob: 30.140625 Frame: images/90_s_Commercials_Ontario_Vol_127_0233.png\n",
      "Log Prob: 27.546875 Frame: images/90_s_Commercials_Ontario_Vol_127_0028.png\n",
      "Log Prob: 27.375 Frame: images/90_s_Commercials_Ontario_Vol_127_0018.png\n",
      "------\n",
      "Processed Volume #128, Highest Log Prob: 23.0, Best frame:, images/90_s_Commercials_Ontario_Vol_128_0181.png\n",
      "------\n",
      "Processed Volume #129, Highest Log Prob: 24.171875, Best frame:, images/90_s_Commercials_Ontario_Vol_129_0145.png\n",
      "------\n",
      "Processed Volume #12, Highest Log Prob: 23.875, Best frame:, images/90_s_Commercials_Ontario_Vol_12_0182.png\n",
      "------\n",
      "Processed Volume #130, Highest Log Prob: 25.484375, Best frame:, images/90_s_Commercials_Ontario_Vol_130_0059.png\n",
      "------\n",
      "Processed Volume #131, Highest Log Prob: 26.28125, Best frame:, images/90_s_Commercials_Ontario_Vol_131_0126.png\n",
      "------\n",
      "Processed Volume #132, Highest Log Prob: 25.796875, Best frame:, images/90_s_Commercials_Ontario_Vol_132_0115.png\n",
      "------\n",
      "Processed Volume #133, Highest Log Prob: 26.15625, Best frame:, images/90_s_Commercials_Ontario_Vol_133_0256.png\n",
      "------\n",
      "Processed Volume #134, Highest Log Prob: 26.1875, Best frame:, images/90_s_Commercials_Ontario_Vol_134_0075.png\n",
      "------\n",
      "Processed Volume #135, Highest Log Prob: 22.296875, Best frame:, images/90_s_Commercials_Ontario_Vol_135_0132.png\n",
      "------\n",
      "Processed Volume #136, Highest Log Prob: 23.5625, Best frame:, images/90_s_Commercials_Ontario_Vol_136_0066.png\n",
      "------\n",
      "Processed Volume #137, Highest Log Prob: 25.0625, Best frame:, images/90_s_Commercials_Ontario_Vol_137_0234.png\n",
      "------\n",
      "Processed Volume #138, Highest Log Prob: 25.921875, Best frame:, images/90_s_Commercials_Ontario_Vol_138_0011.png\n",
      "------\n",
      "Processed Volume #139, Highest Log Prob: 25.125, Best frame:, images/90_s_Commercials_Ontario_Vol_139_0132.png\n",
      "------\n",
      "Processed Volume #13, Highest Log Prob: 25.859375, Best frame:, images/90_s_Commercials_Ontario_Vol_13_0027.png\n",
      "------\n",
      "Processed Volume #140, Highest Log Prob: 28.46875, Best frame:, images/90_s_Commercials_Ontario_Vol_140_0040.png\n",
      "-------\n",
      "MATCH > 27:\n",
      "Log Prob: 28.46875 Frame: images/90_s_Commercials_Ontario_Vol_140_0040.png\n",
      "------\n",
      "Processed Volume #141, Highest Log Prob: 28.109375, Best frame:, images/90_s_Commercials_Ontario_Vol_141_0411.png\n",
      "-------\n",
      "MATCH > 27:\n",
      "Log Prob: 28.109375 Frame: images/90_s_Commercials_Ontario_Vol_141_0411.png\n",
      "Log Prob: 27.34375 Frame: images/90_s_Commercials_Ontario_Vol_141_0412.png\n",
      "------\n",
      "Processed Volume #142, Highest Log Prob: 26.359375, Best frame:, images/90_s_Commercials_Ontario_Vol_142_0204.png\n",
      "------\n",
      "Processed Volume #143, Highest Log Prob: 24.734375, Best frame:, images/90_s_Commercials_Ontario_Vol_143_0188.png\n",
      "------\n",
      "Processed Volume #144, Highest Log Prob: 24.296875, Best frame:, images/90_s_Commercials_Ontario_Vol_144_0166.png\n",
      "------\n",
      "Processed Volume #145, Highest Log Prob: 23.890625, Best frame:, images/90_s_Commercials_Ontario_Vol_145_0027.png\n",
      "------\n",
      "Processed Volume #146, Highest Log Prob: 24.84375, Best frame:, images/90_s_Commercials_Ontario_Vol_146_0188.png\n",
      "------\n",
      "Processed Volume #147, Highest Log Prob: 23.140625, Best frame:, images/90_s_Commercials_Ontario_Vol_147_0172.png\n",
      "------\n",
      "Processed Volume #148, Highest Log Prob: 25.109375, Best frame:, images/90_s_Commercials_Ontario_Vol_148_0214.png\n",
      "------\n",
      "Processed Volume #149, Highest Log Prob: 23.328125, Best frame:, images/90_s_Commercials_Ontario_Vol_149_0036.png\n",
      "------\n",
      "Processed Volume #14, Highest Log Prob: 23.4375, Best frame:, images/90_s_Commercials_Ontario_Vol_14_0201.png\n",
      "------\n",
      "Processed Volume #150, Highest Log Prob: 25.59375, Best frame:, images/90_s_Commercials_Ontario_Vol_150_0283.png\n",
      "------\n",
      "Processed Volume #151, Highest Log Prob: 23.28125, Best frame:, images/90_s_Commercials_Ontario_Vol_151_0129.png\n",
      "------\n",
      "Processed Volume #152, Highest Log Prob: 26.140625, Best frame:, images/90_s_Commercials_Ontario_Vol_152_0092.png\n",
      "------\n",
      "Processed Volume #153, Highest Log Prob: 25.84375, Best frame:, images/90_s_Commercials_Ontario_Vol_153_0162.png\n",
      "------\n",
      "Processed Volume #154, Highest Log Prob: 25.78125, Best frame:, images/90_s_Commercials_Ontario_Vol_154_0278.png\n",
      "------\n",
      "Processed Volume #155, Highest Log Prob: 24.859375, Best frame:, images/90_s_Commercials_Ontario_Vol_155_0200.png\n",
      "------\n",
      "Processed Volume #156, Highest Log Prob: 26.40625, Best frame:, images/90_s_Commercials_Ontario_Vol_156_0252.png\n",
      "------\n",
      "Processed Volume #157, Highest Log Prob: 25.90625, Best frame:, images/90_s_Commercials_Ontario_Vol_157_0160.png\n",
      "------\n",
      "Processed Volume #158, Highest Log Prob: 25.09375, Best frame:, images/90_s_Commercials_Ontario_Vol_158_0172.png\n",
      "------\n",
      "Processed Volume #159, Highest Log Prob: 25.96875, Best frame:, images/90_s_Commercials_Ontario_Vol_159_0082.png\n",
      "------\n",
      "Processed Volume #15, Highest Log Prob: 23.65625, Best frame:, images/90_s_Commercials_Ontario_Vol_15_0292.png\n",
      "------\n",
      "Processed Volume #160, Highest Log Prob: 24.703125, Best frame:, images/90_s_Commercials_Ontario_Vol_160_0035.png\n",
      "------\n",
      "Processed Volume #161, Highest Log Prob: 24.359375, Best frame:, images/90_s_Commercials_Ontario_Vol_161_0154.png\n",
      "------\n",
      "Processed Volume #162, Highest Log Prob: 23.171875, Best frame:, images/90_s_Commercials_Ontario_Vol_162_0006.png\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "all_matches = []\n",
    "\n",
    "for (k,v) in grouped_image_names.items():\n",
    "    vitd = []\n",
    "    for image in v:\n",
    "        vitd.append(preprocess(Image.open(image)).unsqueeze(0))\n",
    "        \n",
    "    text = clip.tokenize([\"an old cartoon elf with a beard\"]).to(device)\n",
    "    t = torch.cat(vitd, dim=0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        image_features = model.encode_image(t)\n",
    "        text_features = model.encode_text(text)\n",
    "\n",
    "        logits_per_image, logits_per_text = model(t, text)\n",
    "        probs = logits_per_image.cpu().numpy()\n",
    "\n",
    "    log_probs = [x[0] for x in probs]\n",
    "\n",
    "    top_20 = sorted(range(len(log_probs)), key=lambda i: log_probs[i])[-20:]\n",
    "    \n",
    "    print(f\"Processed Volume #{k}, Highest Log Prob: {log_probs[top_20[-1]]}, Best frame:, {v[top_20[-1]]}\")\n",
    "    if (log_probs[top_20[-1]] > 27):\n",
    "        print(\"-------\")\n",
    "        print(\"MATCH > 27:\")\n",
    "        for i in range(1,19):\n",
    "            if (log_probs[top_20[-i]]) > 27:\n",
    "                print(f\"Log Prob: {log_probs[top_20[-i]]} Frame: {v[top_20[-i]]}\")\n",
    "                all_matches.append((log_probs[top_20[-i]], v[top_20[-i]]))\n",
    "    print(\"------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10e45d8-3325-4107-b4b5-d4127960104f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
